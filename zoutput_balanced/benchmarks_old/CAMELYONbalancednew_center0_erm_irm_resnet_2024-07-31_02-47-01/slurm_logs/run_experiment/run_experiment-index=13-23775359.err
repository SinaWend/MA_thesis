Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 2
Rules claiming more threads will be scaled down.
Provided resources: mem_mb=100000, mem_mib=95368, disk_mb=1000, disk_mib=954, nvidia_gpu=1
Select jobs to execute...

[Wed Jul 31 02:50:21 2024]
rule run_experiment:
    input: zoutput/benchmarks/CAMELYONbalancednew_center0_dinov2small_erm_irm_resnet_vit_2024-07-31_02-47-01/hyperparameters.csv
    output: zoutput/benchmarks/CAMELYONbalancednew_center0_dinov2small_erm_irm_resnet_vit_2024-07-31_02-47-01/rule_results/13.csv
    jobid: 0
    reason: Forced execution
    wildcards: index=13
    resources: mem_mb=100000, mem_mib=95368, disk_mb=1000, disk_mib=954, tmpdir=/tmp, partition=gpu_p, qos=gpu_normal, nvidia_gpu=1

Failed to import backpack: cannot import name '_grad_input_padding' from 'torch.nn.grad' (/home/aih/sina.wendrich/miniconda3/envs/domainlab_py310/lib/python3.10/site-packages/torch/nn/grad.py)
before experiment loop: 
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

before experiment starts
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|


overriding args.task None to dset


using device: cuda:0

/home/aih/sina.wendrich/miniconda3/envs/domainlab_py310/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.
  warnings.warn(warning.format(ret))
/home/aih/sina.wendrich/miniconda3/envs/domainlab_py310/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.
  warnings.warn(*args, **kwargs)



!!!: not committed yet
/ictstr01/home/aih/sina.wendrich/MA_thesis/DomainLab/domainlab/utils/get_git_tag.py:16: UserWarning: !!!: not committed yet
  warnings.warn("!!!: not committed yet")



b'8efecac6'
model name: dset_te_center0_erm_b8efecac6_not_commited_2024md_07md_31_02_59_40_seed_0_23775359

 Experiment start at: 2024-07-31 02:59:41.333595
/home/aih/sina.wendrich/miniconda3/envs/domainlab_py310/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at /opt/conda/conda-bld/pytorch_1712608935911/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return F.conv2d(input, weight, bias, self.stride,
before training, model accuracy: 0.923138439655304
epoch: 1
---- Training Domain: 
scalar performance:
{'acc': 0.98835427, 'precision': 0.98848945, 'recall': 0.98836076, 'specificity': 0.98836076, 'f1': 0.9883535, 'auroc': 0.99912864, 'binary_precision': 0.9968101, 'binary_recall': 0.97986203, 'binary_specificity': 0.9968595, 'binary_f1_score': 0.98826337}
confusion matrix:
       0      1
0  28568     90
1    578  28124
---- Validation: 
/home/aih/sina.wendrich/miniconda3/envs/domainlab_py310/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at /opt/conda/conda-bld/pytorch_1712608935911/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return F.conv2d(input, weight, bias, self.stride,
scalar performance:
{'acc': 0.96152616, 'precision': 0.71537834, 'recall': 0.75356483, 'specificity': 0.75356483, 'f1': 0.7327126, 'auroc': 0.94117737, 'binary_precision': 0.44750655, 'binary_recall': 0.5303266, 'binary_specificity': 0.9768031, 'binary_f1_score': 0.48540923}
confusion matrix:
       0    1
0  17728  421
1    302  341
---- Test Domain (oracle): 
scalar performance:
{'acc': 0.9610099, 'precision': 0.85983205, 'recall': 0.5472257, 'specificity': 0.5472257, 'f1': 0.575052, 'auroc': 0.9265003, 'binary_precision': 0.75757575, 'binary_recall': 0.09578544, 'binary_specificity': 0.998666, 'binary_f1_score': 0.17006803}
confusion matrix:
      0   1
0  5989   8
1   236  25
new oracle model saved
better model found
persisted
after epoch: 1,now: 2024-07-31 03:24:55.698186,epoch time: 0:25:14.364591,used: 0:25:14.364591,model: dset_te_center0_erm_b8efecac6_not_commited_2024md_07md_31_02_59_40_seed_0_23775359
working direcotry: /ictstr01/home/aih/sina.wendrich/MA_thesis/DomainLab
epoch: 2
---- Training Domain: 
scalar performance:
{'acc': 0.995537, 'precision': 0.99553764, 'recall': 0.9955366, 'specificity': 0.9955366, 'f1': 0.9955369, 'auroc': 0.9998703, 'binary_precision': 0.99512637, 'binary_recall': 0.99595845, 'binary_specificity': 0.9951148, 'binary_f1_score': 0.9955422}
confusion matrix:
       0      1
0  28518    140
1    116  28586
---- Validation: 
scalar performance:
{'acc': 0.95764154, 'precision': 0.69410455, 'recall': 0.7425531, 'specificity': 0.7425531, 'f1': 0.7152566, 'auroc': 0.9194816, 'binary_precision': 0.405672, 'binary_recall': 0.5116641, 'binary_specificity': 0.9734421, 'binary_f1_score': 0.4525447}
confusion matrix:
       0    1
0  17667  482
1    314  329
---- Test Domain (oracle): 
scalar performance:
{'acc': 0.9707574, 'precision': 0.81992745, 'recall': 0.807006, 'specificity': 0.807006, 'f1': 0.81331754, 'auroc': 0.9393667, 'binary_precision': 0.656, 'binary_recall': 0.62835246, 'binary_specificity': 0.9856595, 'binary_f1_score': 0.64187866}
confusion matrix:
      0    1
0  5911   86
1    97  164
new oracle model saved
early stop counter: 1
val acc:0.9576415419578552, best validation acc: 0.9615261554718018, corresponding to test acc:                         0.9610099196434021 / 0.9707574248313904
after epoch: 2,now: 2024-07-31 03:49:59.661912,epoch time: 0:25:03.963726,used: 0:50:18.328317,model: dset_te_center0_erm_b8efecac6_not_commited_2024md_07md_31_02_59_40_seed_0_23775359
working direcotry: /ictstr01/home/aih/sina.wendrich/MA_thesis/DomainLab
epoch: 3
---- Training Domain: 
scalar performance:
{'acc': 0.99295676, 'precision': 0.9930283, 'recall': 0.9929613, 'specificity': 0.9929613, 'f1': 0.9929565, 'auroc': 0.9996308, 'binary_precision': 0.9991533, 'binary_recall': 0.98676, 'binary_specificity': 0.99916255, 'binary_f1_score': 0.992918}
confusion matrix:
       0      1
0  28635     24
1    380  28321
---- Validation: 
scalar performance:
{'acc': 0.9551405, 'precision': 0.643707, 'recall': 0.6204993, 'specificity': 0.6204993, 'f1': 0.6309155, 'auroc': 0.9103294, 'binary_precision': 0.31343284, 'binary_recall': 0.26127526, 'binary_specificity': 0.9797234, 'binary_f1_score': 0.28498727}
confusion matrix:
       0    1
0  17781  368
1    475  168
---- Test Domain (oracle): 
slurmstepd: error: *** JOB 23775359 ON supergpu03 CANCELLED AT 2024-07-31T04:14:48 ***
